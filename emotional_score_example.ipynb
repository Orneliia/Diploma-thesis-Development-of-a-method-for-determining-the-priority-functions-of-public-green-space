{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Sandrro/emotions_classificator\"\n",
    "\n",
    "# Загружаем токенизатор и модель\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Создаем пайплайн для классификации\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    try:\n",
    "        # Убедимся, что текст является строкой\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        \n",
    "        # Обрезаем текст до 512 символов\n",
    "        truncated_text = text[:512]\n",
    "        \n",
    "        # Применяем классификатор с return_all_scores=True\n",
    "        results = classifier(truncated_text, truncation=True)\n",
    "        \n",
    "        # Преобразуем список результатов в словарь\n",
    "        scores = {result['label']: result['score'] for result in results[0]}\n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке текста: {e}\")\n",
    "        return {\"positive\": 0, \"neutral\": 0, \"negative\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_gdf = gpd.read_file(gpd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем функцию ко всем строкам GeoDataFrame\n",
    "emotional_gdf['emotion_scores'] = emotional_gdf['text'].apply(classify_text)\n",
    "\n",
    "# Преобразуем словари с вероятностями в отдельные столбцы\n",
    "emotion_df = pd.json_normalize(emotional_gdf['emotion_scores'])\n",
    "\n",
    "# Объединяем вероятности с исходным GeoDataFrame\n",
    "emotional_gdf = emotional_gdf.join(emotion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгруппируем данные по паркам\n",
    "grouped = emotional_gdf.groupby('name').agg({\n",
    "    'positive': 'sum',\n",
    "    'neutral': 'sum',\n",
    "    'negative': 'sum',\n",
    "    'geometry': 'first'  # Используем первую геометрию (или объединение, если нужно)\n",
    "})\n",
    "\n",
    "# Нормализуем вероятности для каждого парка\n",
    "emotion_columns = ['positive', 'neutral', 'negative']\n",
    "grouped[emotion_columns] = grouped[emotion_columns].div(grouped[emotion_columns].sum(axis=1), axis=0)\n",
    "\n",
    "# Преобразуем результат обратно в GeoDataFrame\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped, geometry='geometry')\n",
    "\n",
    "# Сохраняем результат в файл GeoJSON\n",
    "grouped_gdf.to_file(\"output_with_emotional_scores.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(\"Анализ завершён. Итоговые данные сохранены в 'output_with_emotional_scores.geojson'.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
